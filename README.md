# ğŸ¬ Proyecto DataOps â€“ Disney+ ETL Pipeline

Este proyecto implementa un pipeline ETL automatizado para procesar y analizar datos de tÃ­tulos disponibles en la plataforma Disney+, utilizando Python, Docker, Git y Jenkins como parte de una soluciÃ³n basada en DataOps.

## ğŸ“Œ Objetivo

Extraer datos desde una base de datos **PostgreSQL** con informaciÃ³n de pelÃ­culas y series de Disney+, transformarlos en distintos reportes analÃ­ticos y exportarlos automÃ¡ticamente a un archivo Excel estructurado. 

---

## âš™ï¸ TecnologÃ­as Utilizadas

- ğŸ Python 3 (ETL)
- ğŸ³ Docker (ContenerizaciÃ³n)
- ğŸ› ï¸ Jenkins (AutomatizaciÃ³n CI/CD)
- ğŸ—„ï¸ PostgreSQL (Fuente de datos)
- ğŸ§ª Pandas / OpenPyXL
- ğŸ—ƒï¸ Git + GitHub (Control de versiones)

---

## ğŸ”„ Flujo ETL

### 1. ExtracciÃ³n
Se conecta a una base de datos PostgreSQL y se extrae la tabla `movies`.

### 2. TransformaciÃ³n
Se realizan limpiezas y transformaciones para obtener:

- `df_country_top`: Top 10 paÃ­ses con mÃ¡s contenido.
- `df_added_by_year`: Cantidad de tÃ­tulos agregados por aÃ±o.
- `df_rating_count`: Conteo de tÃ­tulos por clasificaciÃ³n.
- `df_top_directors`: Directores con mÃ¡s tÃ­tulos.
- `df_top_cast`: Actores y actrices mÃ¡s frecuentes.

### 3. Carga
Se exportan todos los resultados a un archivo Excel llamado `disney_data_summary.xlsx`, con cada reporte en una hoja diferente.

---